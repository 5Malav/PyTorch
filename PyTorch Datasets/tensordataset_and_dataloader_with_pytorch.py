# -*- coding: utf-8 -*-
"""TensorDataset and DataLoader with PyTorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Aj6BfMMt2BQSghUjZo7KpEZ5K2lYmP38

#Datasets with PyTorch

we are gonna focus on how to actually read end data with PyTorch.

Particularly how to use PyTorch's built in dataset utility functions
"""

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
#matplotlib inline

from sklearn.model_selection import train_test_split
from torch.utils.data import TensorDataset,DataLoader

df =  pd.read_csv("iris.csv")
df

df.head()

df.columns

df.info()

df.shape

fig,axes = plt.subplots(nrows=2,ncols=2,figsize=(10,7))

#This line creates a figure with a 2x2 grid of subplots,
#setting the figure size to 10x7 inches.
#The fig variable represents the entire figure,
#while axes is an array of the individual subplot objects.

fig.tight_layout()

#This line adjusts the spacing between subplots to
#prevent labels and titles from overlapping.

plots= [(0,1),(2,3),(0,2),(1,3)] # combinations of each column
colors=['b','r','g']
labels=['Iris setosa','Iris virginica','Iris versicolor']

"""
These lines define lists for plot indices, colors, and labels.

plots: A list of tuples, where each tuple represents the
       indices of columns to be plotted in each subplot.

colors: A list of colors for the different data classes.

labels: A list of labels for the legend, corresponding to the different data classes.
"""

for i,ax in enumerate(axes.flat):
    for j in range(3):

        x = df.columns[plots[i][0]]
        y = df.columns[plots[i][1]]

        ax.scatter(df[df['target']==j][x],\
                   df[df['target']==j][y],
                    color=colors[j])
        ax.set(xlabel=x,ylabel=y)

"""
This is a nested loop that iterates through each subplot and each data class (target value).

for i,ax in enumerate(axes.flat): loops through each subplot in the axes array.

for j in range(3): loops through the different target values (0, 1, and 2).

x = df.columns[plots[i][0]] and y = df.columns[plots[i][1]] get
the column names for the x and y axes based on the plots list.

ax.scatter(...) creates a scatter plot of the data points where
target equals j, using the specified color.

ax.set(xlabel=x,ylabel=y) sets the labels for the x and y axes.

"""
fig.legend(labels=labels,loc=3,bbox_to_anchor=(1.0,0.85))
plt.show()

#fig.legend(...) adds a legend to the figure using the labels defined earlier.

#plt.show() displays the plot.

# train test

features = df.drop('target',axis=1).values
features

# .values will print as an array not as dataframe

label = df['target'].values
label

X_train,X_test,y_train,y_test=train_test_split(features,label,
                 test_size=0.2,random_state=33)

X_train.shape

#covert X_train numpy array in torch tensor

X_train = torch.FloatTensor(X_train)

X_test = torch.FloatTensor(X_test)

y_train = torch.LongTensor(y_train)

y_test = torch.LongTensor(y_test)

y_train

y_test

# reshape y_train and y_test so we can get them as column
# instead of long vector

y_train = torch.LongTensor(y_train).reshape(-1,1)

y_test = torch.LongTensor(y_test).reshape(-1,1)

y_train

y_test

from torch.utils.data import TensorDataset,DataLoader

df

data= df.drop('target',axis=1).values

labels = df['target'].values

iris = TensorDataset(torch.FloatTensor(data),torch.LongTensor(labels))
iris

len(iris)

for i in iris:
    print(i)

# TensorDataset will do exact the same that we did earlier
# it is in inbuilt function in PyTorch library
# which will convert array into tensors.

# from the data we can see that it contains both features
# as their own specialized tensor and then the label as
# its own tensor.
# features will be float because of FloatTensor
# labels will be intenger because of LongTensor



# DataLoader
# Idea is that once we have our data essentially coverted
# to this TensorDataset object, we can wrap with
# DataLoader which is very convenient loader object that
# can be used for large neural networks that can shuffle the data
# and actully produce the batches of the data

# That's why TensorDataset is important.
# because when we work with neural network we will not
# feed all the data at once, especially when we work
# with huge dataset such as 100k samples,

# we don't wanna feed all sample at once.
# Instead, we grabe little random bactches from the data
# and then feed those in until you have gone through all the
# training data one time.And then that's 1 epoch
# so that's where the term batch comes in.

# if we start doing it the manually way with train_test_split
# we have to figure our our own functionalities for actually
# splitting things up into batches and feeding those in
# if we have large datasets.

iris_loader=DataLoader(iris,batch_size=50,shuffle=True)
iris_loader

# each batch will have 50 rows

for i_batch,sample_batch in enumerate(iris_loader):
        print(i_batch,sample_batch)
#print data with batch number

#for batch in iris_loader:
#    print(batch)
# this will not give batch number















